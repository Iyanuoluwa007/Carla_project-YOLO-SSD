{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbf8dd9-5311-42b0-b95b-11b8550d0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9d7574-b01a-4de0-8fda-aa604a08236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new client instance\n",
    "client = carla.Client('localhost', 2000)\n",
    "world = client.get_world()\n",
    "\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "vehicle_bp = bp_lib.find('vehicle.dodge.charger')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "spectator = world.get_spectator()\n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4, z=2.5)), vehicle.get_transform().rotation)\n",
    "spectator.set_transform(transform)\n",
    "\n",
    "CarlaSetup = subprocess.Popen(['python', 'carla_setup.py'])\n",
    "# print(\"Carla world is running in background!\")\n",
    "# time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f1c804-9fcc-4321-b834-38b80f007271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traffic light control is running in the background!\n",
      "Traffic generation is running in the background!\n"
     ]
    }
   ],
   "source": [
    "# Start the traffic light controller in the background\n",
    "traffic_light_process = subprocess.Popen(['python', 'traffic_light_controller.py'])\n",
    "print(\"Traffic light control is running in the background!\")\n",
    "\n",
    "# Start the traffic script in the background\n",
    "traffic_process = subprocess.Popen(['python', 'generate_traffic.py', '--number-of-vehicles', '30', '--number-of-walkers', '100'])\n",
    "\n",
    "print(\"Traffic generation is running in the background!\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Set up traffic manager\n",
    "traffic_manager = client.get_trafficmanager()\n",
    "vehicle.set_autopilot(True, traffic_manager.get_port())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8949758e-90f9-4aa6-ae80-a9d736b79646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DVS camera settings updated!\n",
      "‚úÖ Optical Flow camera settings updated!\n"
     ]
    }
   ],
   "source": [
    "# Cameras Call\n",
    "# camera_init_trans = carla.Transform(carla.Location(z=1.6, x=0.1))\n",
    "# Correct sensor placement relative to the vehicle\n",
    "camera_init_trans = carla.Transform(carla.Location(x=0.0, y=0.0, z=1.6), carla.Rotation(pitch=0.0))\n",
    "\n",
    "\n",
    "\n",
    "# # Set Camera Attributes Before Spawning\n",
    "# def set_camera_attributes(camera_bp):\n",
    "#     camera_bp.set_attribute('image_size_x', '800')\n",
    "#     camera_bp.set_attribute('image_size_y', '600')\n",
    "#     camera_bp.set_attribute('fov', '90')\n",
    "\n",
    "def set_camera_attributes(camera_bp):\n",
    "    if \"optical_flow\" in camera_bp.id:\n",
    "        camera_bp.set_attribute('image_size_x', '1280')  # High resolution\n",
    "        camera_bp.set_attribute('image_size_y', '720')\n",
    "        camera_bp.set_attribute('fov', '120')\n",
    "        camera_bp.set_attribute('sensor_tick', '0.05')  # Capture every 0.05s\n",
    "        print(\"‚úÖ Optical Flow camera settings updated!\")\n",
    "\n",
    "    elif \"dvs\" in camera_bp.id:\n",
    "        camera_bp.set_attribute('image_size_x', '1280')\n",
    "        camera_bp.set_attribute('image_size_y', '720')\n",
    "        camera_bp.set_attribute('fov', '120')\n",
    "        camera_bp.set_attribute('sensor_tick', '0.01')  # Higher frequency\n",
    "        camera_bp.set_attribute('positive_threshold', '0.2')  # Lower threshold to detect small brightness changes\n",
    "        camera_bp.set_attribute('negative_threshold', '0.2')\n",
    "        camera_bp.set_attribute('refractory_period_ns', '100000')  # Short refractory period (100¬µs)\n",
    "        print(\"‚úÖ DVS camera settings updated!\")\n",
    "\n",
    "    else:  # Default settings for all other cameras\n",
    "        camera_bp.set_attribute('image_size_x', '800')\n",
    "        camera_bp.set_attribute('image_size_y', '600')\n",
    "        camera_bp.set_attribute('fov', '90')  # Default settings\n",
    "        \n",
    "# RGB camera\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "set_camera_attributes(camera_bp)\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Semantic camera\n",
    "sem_camera_bp = bp_lib.find('sensor.camera.semantic_segmentation')\n",
    "set_camera_attributes(sem_camera_bp)\n",
    "sem_camera = world.spawn_actor(sem_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Instance Seg camera\n",
    "inst_camera_bp = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "set_camera_attributes(inst_camera_bp)\n",
    "inst_camera = world.spawn_actor(inst_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Monocular Depth camera\n",
    "depth_camera_bp = bp_lib.find('sensor.camera.depth')\n",
    "set_camera_attributes(depth_camera_bp)\n",
    "depth_camera = world.spawn_actor(depth_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# DVS camera\n",
    "dvs_camera_bp = bp_lib.find('sensor.camera.dvs')\n",
    "set_camera_attributes(dvs_camera_bp)\n",
    "dvs_camera = world.spawn_actor(dvs_camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "\n",
    "# Optical Flow camera\n",
    "opt_camera_bp = bp_lib.find('sensor.camera.optical_flow')\n",
    "set_camera_attributes(opt_camera_bp)\n",
    "opt_camera = world.spawn_actor(opt_camera_bp, camera_init_trans, attach_to=vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad16b0b1-c1ff-4cf4-8fa6-602ab4b769e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DVS Camera is correctly attached to: vehicle.dodge.charger\n",
      "‚úÖ Optical Flow Camera is correctly attached to: vehicle.dodge.charger\n"
     ]
    }
   ],
   "source": [
    "# Check if DVS Camera is attached correctly\n",
    "if dvs_camera:\n",
    "    dvs_parent = dvs_camera.parent\n",
    "    if dvs_parent:\n",
    "        print(f\"‚úÖ DVS Camera is correctly attached to: {dvs_parent.type_id}\")\n",
    "    else:\n",
    "        print(\"‚ùå DVS Camera is not attached to any actor!\")\n",
    "\n",
    "# Check if Optical Flow Camera is attached correctly\n",
    "if opt_camera:\n",
    "    opt_parent = opt_camera.parent\n",
    "    if opt_parent:\n",
    "        print(f\"‚úÖ Optical Flow Camera is correctly attached to: {opt_parent.type_id}\")\n",
    "    else:\n",
    "        print(\"‚ùå Optical Flow Camera is not attached to any actor!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf39073-20ec-4b25-8415-f2d94af55eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DVS Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n",
      "‚úÖ Optical Flow Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n",
      "‚úÖ RGB Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n",
      "‚úÖ Sem Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n",
      "‚úÖ Inst Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n",
      "‚úÖ Depth Camera spawned at Transform(Location(x=-15.124249, y=69.708885, z=1.488181), Rotation(pitch=0.458488, yaw=0.066119, roll=-0.194225))\n"
     ]
    }
   ],
   "source": [
    "if dvs_camera is None:\n",
    "    print(\"‚ùå Error: DVS Camera failed to spawn!\")\n",
    "    exit()  # Stop execution if the sensor fails to spawn\n",
    "else:\n",
    "    print(f\"‚úÖ DVS Camera spawned at {dvs_camera.get_transform()}\")\n",
    "\n",
    "if opt_camera is None:\n",
    "    print(\"‚ùå Error: Optical Flow Camera failed to spawn!\")\n",
    "    exit()  # Stop execution if the sensor fails to spawn\n",
    "else:\n",
    "    print(f\"‚úÖ Optical Flow Camera spawned at {opt_camera.get_transform()}\")\n",
    "\n",
    "if camera is None:\n",
    "    print(\"‚ùå Error: RGB Camera failed to spawn!\")\n",
    "else:\n",
    "    print(f\"‚úÖ RGB Camera spawned at {camera.get_transform()}\")\n",
    "\n",
    "if sem_camera is None:\n",
    "    print(\"‚ùå Error: Sem Camera failed to spawn!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Sem Camera spawned at {sem_camera.get_transform()}\")\n",
    "\n",
    "if inst_camera is None:\n",
    "    print(\"‚ùå Error: Inst Camera failed to spawn!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Inst Camera spawned at {inst_camera.get_transform()}\")\n",
    "\n",
    "if depth_camera is None:\n",
    "    print(\"‚ùå Error: Depth Camera failed to spawn!\")\n",
    "else:\n",
    "    print(f\"‚úÖ Depth Camera spawned at {depth_camera.get_transform()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acf838ca-94cb-4eda-9a02-e8c60f4e0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get image dimensions\n",
    "# image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "# image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "# # Initialize sensor data storage\n",
    "# sensor_data = {\n",
    "#     'rgb_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "#     'sem_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "#     'depth_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "#     'dvs_image': np.zeros((image_h, image_w, 3), dtype=np.uint8),  # DVS doesn't need 4 channels\n",
    "#     'opt_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "#     'inst_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "# }\n",
    "\n",
    "# Initialize sensor data storage BEFORE calling `listen()`\n",
    "image_w = 800\n",
    "image_h = 600\n",
    "\n",
    "sensor_data = {\n",
    "    'rgb_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'sem_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'depth_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "    'dvs_image': np.zeros((image_h, image_w, 3), dtype=np.uint8),  # DVS uses 3 channels\n",
    "    'opt_image': np.zeros((image_h, image_w, 3), dtype=np.uint8),  # Optical Flow uses 3 channels\n",
    "    'inst_image': np.zeros((image_h, image_w, 4), dtype=np.uint8),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e9f0fe-5362-4619-8a50-3b59d65006fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(image, label, position=(10, 50), font_scale=0.8, color=(255, 255, 255)):\n",
    "    \"\"\"Adds a text label to an image.\"\"\"\n",
    "    labeled_image = image.copy()  # Work on a copy to avoid modifying original\n",
    "    cv2.putText(labeled_image, label, position, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                font_scale, color, 2, cv2.LINE_AA)\n",
    "    return labeled_image  # Return the labeled image\n",
    "\n",
    "def rgb_callback(image, data_dict):\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"RGB Camera\")\n",
    "    data_dict['rgb_image'] = img\n",
    "\n",
    "def sem_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Semantic Segmentation\")\n",
    "    data_dict['sem_image'] = img\n",
    "\n",
    "def inst_callback(image, data_dict):\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Instance Segmentation\")\n",
    "    data_dict['inst_image'] = img\n",
    "\n",
    "def depth_callback(image, data_dict):\n",
    "    image.convert(carla.ColorConverter.LogarithmicDepth)\n",
    "    img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    add_label(img, \"Depth Camera\")\n",
    "    data_dict['depth_image'] = img\n",
    "\n",
    "# def opt_callback(image, data_dict):\n",
    "#     img = image.get_color_coded_flow()\n",
    "#     img = np.array(img, dtype=np.uint8)  # Convert to numpy array\n",
    "#     # Ensure Optical Flow visualization is not completely black\n",
    "#     if img.max() == 0:\n",
    "#         img[:, :, :] = 255  # Set white to indicate no data\n",
    "#     else:\n",
    "#         add_label(img, \"Optical Flow\")\n",
    "#     data_dict['opt_image'] = img\n",
    "\n",
    " \n",
    "# def dvs_callback(image, data_dict):\n",
    "#     dvs_events = np.frombuffer(image.raw_data, dtype=np.dtype([\n",
    "#         ('x', np.uint16), ('y', np.uint16), ('t', np.int64), ('pol', np.bool_)]))\n",
    "\n",
    "#     dvs_img = np.zeros((image.height, image.width, 3), dtype=np.uint8)\n",
    "\n",
    "#     if len(dvs_events) > 0:  # Ensure there are DVS events\n",
    "#         dvs_img[dvs_events['y'], dvs_events['x'], dvs_events['pol'] * 2] = 255\n",
    "#         add_label(dvs_img, \"DVS Camera\")\n",
    "#     else:\n",
    "#         dvs_img[:, :, :] = 255  # Set white if no events detected\n",
    "\n",
    "#     data_dict['dvs_image'] = dvs_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645df4d9-4918-4077-92a8-a05d18fbe9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_callback(image, data_dict):\n",
    "    try:\n",
    "        print(f\"üì∑ Optical Flow Image Received: {image.frame}\")\n",
    "\n",
    "        # Convert flow to color image\n",
    "        img = image.get_color_coded_flow()\n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "\n",
    "        # Rescale image to better visualize motion\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "        print(f\"üîç Optical Flow - Max: {img.max()}, Min: {img.min()}, Mean: {np.mean(img)}\")\n",
    "\n",
    "        if img.max() == 0:\n",
    "            print(\"‚ö† Warning: Optical Flow is black (no motion detected)\")\n",
    "            img[:, :, :] = 255  # White fallback\n",
    "\n",
    "        add_label(img, \"Optical Flow\")\n",
    "        data_dict['opt_image'] = img\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Optical Flow processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54588720-5071-4e54-b091-ec639dfbbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dvs_callback(image, data_dict):\n",
    "    try:\n",
    "        dvs_events = np.frombuffer(image.raw_data, dtype=np.dtype([\n",
    "            ('x', np.uint16), ('y', np.uint16), ('t', np.int64), ('pol', np.bool_)]))\n",
    "\n",
    "        dvs_img = np.zeros((image.height, image.width, 3), dtype=np.uint8)\n",
    "\n",
    "        print(f\"üì∏ DVS Events Detected: {len(dvs_events)}\")\n",
    "\n",
    "        if len(dvs_events) > 0:\n",
    "            # Map positive events to red, negative events to blue\n",
    "            dvs_img[dvs_events['y'], dvs_events['x'], 2] = dvs_events['pol'] * 255  # Red for positive\n",
    "            dvs_img[dvs_events['y'], dvs_events['x'], 0] = (1 - dvs_events['pol']) * 255  # Blue for negative\n",
    "            add_label(dvs_img, \"DVS Camera\")\n",
    "        else:\n",
    "            print(\"‚ö† Warning: No DVS events detected\")\n",
    "            dvs_img[:, :, :] = 255  # White fallback\n",
    "\n",
    "        data_dict['dvs_image'] = dvs_img\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in DVS processing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459d6de7-b105-4994-8aa4-41d4cd5a6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_callback(image, data_dict):\n",
    "    print(f\"üì∑ Optical Flow Image Received: {image.frame}\")\n",
    "    # Process normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0577b42d-1cd7-4471-b844-f2398434d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DVS Image Max: 0\n",
      "Optical Flow Image Max: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"DVS Image Max: {np.max(sensor_data['dvs_image'])}\")\n",
    "print(f\"Optical Flow Image Max: {np.max(sensor_data['opt_image'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bc7cca6-ce63-4339-ad38-0e1bd7846d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start sensor listeners\n",
    "camera.listen(lambda image: rgb_callback(image, sensor_data))\n",
    "sem_camera.listen(lambda image: sem_callback(image, sensor_data))\n",
    "inst_camera.listen(lambda image: inst_callback(image, sensor_data))\n",
    "depth_camera.listen(lambda image: depth_callback(image, sensor_data))\n",
    "dvs_camera.listen(lambda image: dvs_callback(image, sensor_data))\n",
    "opt_camera.listen(lambda image: opt_callback(image, sensor_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732b702-467a-47f8-bf40-3d635a81c9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∑ Optical Flow Image Received: 1983\n",
      "üì∑ Optical Flow Image Received: 1984\n",
      "üì∑ Optical Flow Image Received: 1985\n",
      "üì∑ Optical Flow Image Received: 1986\n",
      "üì∑ Optical Flow Image Received: 1987\n",
      "üì∑ Optical Flow Image Received: 1988\n",
      "üì∑ Optical Flow Image Received: 1989\n",
      "üì∑ Optical Flow Image Received: 1990\n",
      "üì∑ Optical Flow Image Received: 1991\n",
      "üì∑ Optical Flow Image Received: 1992\n",
      "üì∑ Optical Flow Image Received: 1993\n",
      "üì∑ Optical Flow Image Received: 1994\n",
      "üì∑ Optical Flow Image Received: 1995\n",
      "üì∑ Optical Flow Image Received: 1996\n",
      "üì∑ Optical Flow Image Received: 1997\n",
      "üì∑ Optical Flow Image Received: 1998\n",
      "üì∑ Optical Flow Image Received: 1999\n",
      "üì∑ Optical Flow Image Received: 2000\n",
      "üì∑ Optical Flow Image Received: 2001\n",
      "üì∑ Optical Flow Image Received: 2002\n",
      "üì∑ Optical Flow Image Received: 2003\n",
      "üì∑ Optical Flow Image Received: 2004\n",
      "üì∑ Optical Flow Image Received: 2005\n"
     ]
    }
   ],
   "source": [
    "# Create display windows\n",
    "cv2.namedWindow('All Cameras', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('All Cameras', 1920, 1080)\n",
    "\n",
    "cv2.namedWindow('Duplicate RGB', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Duplicate RGB', 800, 600)  # Keep RGB window smaller\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"Ensure all images have 3 channels (convert to RGB if needed).\"\"\"\n",
    "    if img.shape[2] == 4:  # If image has 4 channels (RGBA)\n",
    "        img = img[:, :, :3]  # Drop the alpha channel\n",
    "    return img\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Convert all sensor images to 3-channel RGB format\n",
    "        sensor_data_processed = {key: preprocess_image(img) for key, img in sensor_data.items()}\n",
    "\n",
    "        # Check if all images are available before displaying\n",
    "        if any(img.shape[0] == 0 for img in sensor_data_processed.values()):\n",
    "            print(\"Waiting for camera feeds...\")\n",
    "            continue\n",
    "\n",
    "        # Get the RGB image **without** label for the Duplicate RGB window\n",
    "        rgb_clean = sensor_data_processed['rgb_image'].copy()\n",
    "\n",
    "        # Create a **labeled** RGB image for the \"All Cameras\" window\n",
    "        rgb_labeled = add_label(sensor_data_processed['rgb_image'], \"RGB Camera\")\n",
    "\n",
    "        # Concatenate images in a 2-row format for display\n",
    "        top_row = np.concatenate([\n",
    "            rgb_labeled,  # **Labeled RGB Image for \"All Cameras\"**\n",
    "            add_label(sensor_data_processed['sem_image'], \"Semantic Segmentation\"),\n",
    "            add_label(sensor_data_processed['inst_image'], \"Instance Segmentation\")\n",
    "        ], axis=1)\n",
    "        \n",
    "        lower_row = np.concatenate([\n",
    "            add_label(sensor_data_processed['depth_image'], \"Depth Camera\"),\n",
    "            add_label(sensor_data_processed['dvs_image'], \"DVS Camera\"),\n",
    "            add_label(sensor_data_processed['opt_image'], \"Optical Flow\")\n",
    "        ], axis=1)\n",
    "\n",
    "        # Combine both rows into a single tiled view\n",
    "        tiled = np.concatenate((top_row, lower_row), axis=0)\n",
    "\n",
    "        # Display the combined camera feeds in the main window\n",
    "        cv2.imshow('All Cameras', tiled)\n",
    "\n",
    "        # Display the **clean RGB image** in the Duplicate RGB window\n",
    "        cv2.imshow(\"Duplicate RGB\", rgb_clean)\n",
    "\n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying images: {e}\")\n",
    "\n",
    "# Cleanup: Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11e9e4-912f-4714-90cd-154756c37772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_process = subprocess.Popen(['python', 'camera_processing.py'])\n",
    "# print(\"Camera processing is running in the background!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171695a-f9dd-4055-99eb-f9481e123cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
